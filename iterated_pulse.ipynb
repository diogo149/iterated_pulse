{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PULSE import PULSE\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import DataParallel\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from math import log10, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import dlib\n",
    "from drive import open_url\n",
    "from pathlib import Path\n",
    "from bicubic import BicubicDownSample\n",
    "import torchvision\n",
    "from shape_predictor import align_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import stylegan\n",
    "import tempfile\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    input_dir=\"aligned_faces/\",  # 'input data directory'\n",
    "    output_dir='runs',  # 'output data directory'\n",
    "    cache_dir='cache',  # 'cache directory for model weights'\n",
    "    duplicates=1,  # 'How many HR images to produce for every image in the input directory'\n",
    "    batch_size=1,  # 'Batch size to use during optimization'\n",
    "#     seed=0,  # 'manual seed to use'\n",
    "    loss_str=\"100*L2+0.05*GEOCROSS\",  # 'Loss function to use'\n",
    "    eps=2e-3,  # 'Target for downscaling loss (L2)'\n",
    "    noise_type='trainable',  # 'zero, fixed, or trainable'\n",
    "    num_trainable_noise_layers=5,  # 'Number of noise layers to optimize'\n",
    "    tile_latent=False,  # 'Whether to forcibly tile the same latent 18 times'\n",
    "    bad_noise_layers=\"17\",  # 'List of noise layers to zero out to improve image quality')\n",
    "    opt_name='custom',  # 'Optimizer to use in projected gradient descent'\n",
    "    learning_rate=0.4,  #  help='Learning rate to use during optimization'\n",
    "    steps=200,  # 'Number of optimization steps'\n",
    "    lr_schedule='linear1cycledrop',  # 'fixed, linear1cycledrop, linear1cycle'\n",
    "    save_intermediate=False,  # 'Whether to store and save intermediate HR and LR images during optimization'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### align_face.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# cache_dir = Path(kwargs[\"cache_dir\"])\n",
    "# cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# print(\"Downloading Shape Predictor\")\n",
    "# f=open_url(\"https://drive.google.com/uc?id=1huhv8PYpNNKbGCLOaYUjOgR1pY5pmbJx\", cache_dir=cache_dir, return_path=True)\n",
    "# predictor = dlib.shape_predictor(f)\n",
    "\n",
    "unaligned_path = \"unaligned_faces/\"\n",
    "aligned_faces_size = 32\n",
    "f = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(f)\n",
    "\n",
    "for im in Path(unaligned_path).glob(\"*.*\"):\n",
    "    print(im)\n",
    "    faces = align_face(str(im), predictor)\n",
    "\n",
    "    for i, face in enumerate(faces):\n",
    "        target_path = Path(kwargs[\"input_dir\"]) / (im.stem + f\"_{i}.png\")\n",
    "        if not os.path.exists(target_path):\n",
    "            print(face._size)\n",
    "            if aligned_faces_size is not None:\n",
    "                factor = 1024 // aligned_faces_size\n",
    "                assert aligned_faces_size * factor == 1024\n",
    "                D = BicubicDownSample(factor=factor)\n",
    "                face_tensor = torchvision.transforms.ToTensor()(face).unsqueeze(0).cuda()\n",
    "                face_tensor_lr = D(face_tensor)[0].cpu().detach().clamp(0, 1)\n",
    "                face = torchvision.transforms.ToPILImage()(face_tensor_lr)\n",
    "\n",
    "            face.save(target_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Images(Dataset):\n",
    "    def __init__(self, root_dir, duplicates):\n",
    "        self.root_path = Path(root_dir)\n",
    "        self.image_list = list(self.root_path.glob(\"*.png\"))\n",
    "        self.duplicates = duplicates # Number of times to duplicate the image in the dataset to produce multiple HR images\n",
    "        factor = 1024 // 32\n",
    "        self.D = BicubicDownSample(factor=factor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.duplicates*len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_list[idx//self.duplicates]\n",
    "        image = torchvision.transforms.ToTensor()(Image.open(img_path))\n",
    "        # HACK\n",
    "        if image.shape == (3, 1024, 1024):\n",
    "            image = self.D(image.unsqueeze(0).cuda())[0].cpu().detach().clamp(0, 1)\n",
    "        elif image.shape == (3, 32, 32):\n",
    "            # already resized (:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(image.shape)\n",
    "        if(self.duplicates == 1):\n",
    "            return image,img_path.stem\n",
    "        else:\n",
    "            return image,img_path.stem+f\"_{(idx % self.duplicates)+1}\"\n",
    "\n",
    "dataset = Images(kwargs[\"input_dir\"], duplicates=kwargs[\"duplicates\"])\n",
    "out_path = Path(kwargs[\"output_dir\"])\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=kwargs[\"batch_size\"])\n",
    "\n",
    "model = PULSE(cache_dir=kwargs[\"cache_dir\"])\n",
    "# removed because of error:\n",
    "# TypeError: forward() missing 1 required positional argument: 'ref_im'\n",
    "# model = DataParallel(model)\n",
    "\n",
    "toPIL = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load images\n",
    "ref_imgs = {}\n",
    "for ref_im, ref_im_name_tuple in dataloader:\n",
    "    ref_imgs[ref_im_name_tuple[0]] = ref_im.cuda()\n",
    "print(ref_imgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d_basic = stylegan.D_basic()\n",
    "d_basic.load_state_dict(torch.load(\"karras2019stylegan-ffhq-1024x1024.for_d_basic.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpendicular(v):\n",
    "    t = np.random.randn(*v.shape)\n",
    "    t -= t.flatten().dot(v.flatten()) * v / v.flatten().dot(v.flatten())\n",
    "    t *= np.linalg.norm(v) / np.linalg.norm(t)\n",
    "    return t\n",
    "\n",
    "def perpendicular_multi(vs, initial=None):\n",
    "    def _perpendicular(v, t):\n",
    "        # makes t perpendicular to v\n",
    "        t -= t.flatten().dot(v.flatten()) * v / v.flatten().dot(v.flatten())\n",
    "        t *= np.linalg.norm(v) / np.linalg.norm(t)\n",
    "        return t\n",
    "\n",
    "    vs_orig = vs\n",
    "    vs = list(vs)  # make a copy\n",
    "    # this final one should be perpendicular to all\n",
    "    if initial is None:\n",
    "        vs.append(np.random.randn(*vs[0].shape))\n",
    "    else:\n",
    "        vs.append(initial)\n",
    "    for i in range(len(vs) - 1):\n",
    "        for j in range(i + 1, len(vs)):\n",
    "            vs[j] = _perpendicular(vs[i], vs[j])\n",
    "    # print([vs[-1].flatten().dot(v.flatten()) for v in vs_orig])\n",
    "    return vs[-1]\n",
    "\n",
    "def negation_init(prev_results):\n",
    "    if not prev_results:\n",
    "        return None\n",
    "\n",
    "    def _negation_reduce(vs):\n",
    "        avg_v = sum(vs) / len(vs)\n",
    "        avg_norm = np.mean([np.linalg.norm(v) for v in vs])\n",
    "        v = -avg_v\n",
    "        v *= avg_norm / np.linalg.norm(v)\n",
    "        return v\n",
    "\n",
    "    var_list_initial_values = []\n",
    "    for var_idx in range(len(prev_results[0][\"var_list\"])):\n",
    "        prev_vars = [result[\"var_list\"][var_idx].detach().cpu().numpy()\n",
    "                     for result in prev_results]\n",
    "        var_list_initial_values.append(torch.tensor(\n",
    "            _negation_reduce(prev_vars)))\n",
    "    return var_list_initial_values\n",
    "\n",
    "def perpendicular_init(prev_results):\n",
    "    if not prev_results:\n",
    "        return None\n",
    "    var_list_initial_values = []\n",
    "    for var_idx in range(len(prev_results[0][\"var_list\"])):\n",
    "        prev_vars = [result[\"var_list\"][var_idx].detach().cpu().numpy()\n",
    "                     for result in prev_results]\n",
    "        var_list_initial_values.append(torch.tensor(\n",
    "            perpendicular_multi(prev_vars)))\n",
    "    return var_list_initial_values\n",
    "\n",
    "def farthest_sampled_init(prev_results):\n",
    "    if not prev_results:\n",
    "        return None\n",
    "    var_list_initial_values = []\n",
    "    for var_idx in range(len(prev_results[0][\"var_list\"])):\n",
    "        prev_vars = [result[\"var_list\"][var_idx].detach().cpu().numpy()\n",
    "                     for result in prev_results]\n",
    "        \n",
    "        n_samples = 10000\n",
    "        prev_shape = prev_vars[0].shape\n",
    "        prev_size = np.prod(prev_shape)\n",
    "        samples = np.random.randn(n_samples, *prev_shape)\n",
    "        num_prev = len(prev_vars)\n",
    "        prev_tensor = np.array(prev_vars).reshape(num_prev, prev_size).T\n",
    "        avg_distance = samples.reshape(-1, prev_size).dot(prev_tensor).mean(axis=1)\n",
    "        best_idx = np.argmin(avg_distance)\n",
    "        best_sample = samples[best_idx]\n",
    "        \n",
    "        sample = best_sample * np.linalg.norm(prev_vars[0]) / np.linalg.norm(best_sample)\n",
    "        \n",
    "        var_list_initial_values.append(torch.tensor(sample))\n",
    "    return var_list_initial_values\n",
    "\n",
    "def make_postprocess_perpendicular_projection(prev_results, only_latents=False):\n",
    "    def step_postprocess(params):\n",
    "        for var_idx in range(len(params)):\n",
    "            if var_idx == 0 or not only_latents:\n",
    "                initial = params[var_idx].detach().cpu().numpy()\n",
    "                prev_vars = [result[\"var_list\"][var_idx].detach().cpu().numpy()\n",
    "                             for result in prev_results]            \n",
    "                updated = perpendicular_multi(prev_vars, initial)\n",
    "                params[var_idx].copy_(torch.from_numpy(updated))\n",
    "\n",
    "    return step_postprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results_with_D(results, num_keep):\n",
    "    with torch.no_grad():\n",
    "        d_scores = [d_basic(res[\"HR\"]).item() for res in results]\n",
    "    # want smallest num_keep scores\n",
    "    keep_scores = list(sorted(d_scores))[:num_keep]\n",
    "    new_results = []\n",
    "    for d_score, res in zip(d_scores, results):\n",
    "        if d_score in keep_scores:\n",
    "            new_results.append(res)\n",
    "    return new_results\n",
    "\n",
    "def sortby_D(results):\n",
    "    with torch.no_grad():\n",
    "        d_scores = [d_basic(res[\"HR\"]).item() for res in results]\n",
    "    return [results[i] for i in np.argsort(d_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    \"vanilla_pulse\",\n",
    "    \"iterative_negation_initialization\",\n",
    "    \"farthest_sampled_initialization\",\n",
    "    \"iterative_perpendicular_initialization\",\n",
    "    \"perpendicular_projection_optimizer\",\n",
    "    \"perpendicular_projection_optimizer_only_latents\",\n",
    "    \"perpendicular_projection_optimizer_psi0.7\",\n",
    "    \"perpendicular_projection_optimizer_discloss\",\n",
    "    \"perpendicular_projection_optimizer_psi0.7_discloss\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration_to_extra_kwargs(c, prev_results):\n",
    "    extra_kwargs = {}\n",
    "    \n",
    "    if c == \"vanilla_pulse\":\n",
    "        var_list_initial_values = None\n",
    "    elif c == \"iterative_negation_initialization\":\n",
    "        var_list_initial_values = negation_init(prev_results)\n",
    "    elif c in {\"iterative_perpendicular_initialization\",\n",
    "               \"perpendicular_projection_optimizer\",\n",
    "               \"perpendicular_projection_optimizer_only_latents\",\n",
    "               \"perpendicular_projection_optimizer_psi0.7\",\n",
    "               \"perpendicular_projection_optimizer_discloss\",\n",
    "               \"perpendicular_projection_optimizer_psi0.7_discloss\"}:\n",
    "        var_list_initial_values = perpendicular_init(prev_results)\n",
    "    elif c == \"farthest_sampled_initialization\":\n",
    "        var_list_initial_values = farthest_sampled_init(prev_results)\n",
    "    else:\n",
    "        raise ValueError(c)\n",
    "    extra_kwargs[\"var_list_initial_values\"] = var_list_initial_values\n",
    "    \n",
    "    if c in {\"perpendicular_projection_optimizer\",\n",
    "             \"perpendicular_projection_optimizer_psi0.7\",\n",
    "             \"perpendicular_projection_optimizer_discloss\",\n",
    "             \"perpendicular_projection_optimizer_psi0.7_discloss\"}:\n",
    "        step_postprocess = make_postprocess_perpendicular_projection(prev_results, only_latents=False)\n",
    "    elif c == \"perpendicular_projection_optimizer_only_latents\":\n",
    "        step_postprocess = make_postprocess_perpendicular_projection(prev_results, only_latents=True)\n",
    "    else:\n",
    "        step_postprocess = None\n",
    "    extra_kwargs[\"step_postprocess\"] = step_postprocess\n",
    "    \n",
    "    if c in {\"perpendicular_projection_optimizer_psi0.7\",\n",
    "             \"perpendicular_projection_optimizer_psi0.7_discloss\"}:\n",
    "        extra_kwargs[\"psi\"] = 0.7\n",
    "        \n",
    "    if c in {\"perpendicular_projection_optimizer_discloss\",\n",
    "             \"perpendicular_projection_optimizer_psi0.7_discloss\"}:\n",
    "        extra_kwargs[\"loss_str\"] = \"100*L2+0.05*GEOCROSS+0.01*DISC\"\n",
    "\n",
    "    return extra_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_grid(all_results, grid_shape, img_prefix, out_dir=\"runs\"):\n",
    "    tmp = np.array(\n",
    "        [r[\"HR\"].numpy() for r in all_results]\n",
    "    ).reshape(\n",
    "        grid_shape[0], grid_shape[1], 3, 1024, 1024\n",
    "    ).transpose(2, 0, 3, 1, 4).reshape(\n",
    "        3, grid_shape[0] * 1024, grid_shape[1] * 1024\n",
    "    )\n",
    "    toPIL(torch.from_numpy(tmp)).save(f\"{out_dir}/{img_prefix}__grid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(t1, t2, alpha):\n",
    "    return t1 * alpha + t2 * (1 - alpha)\n",
    "\n",
    "def spherp(t1, t2, alpha):\n",
    "    t1 = t1.cpu().numpy()\n",
    "    t2 = t2.cpu().numpy()\n",
    "    norm1 = np.linalg.norm(t1) + 1e-8\n",
    "    norm2 = np.linalg.norm(t2) + 1e-8\n",
    "    norm_out = norm1 * alpha + norm2 * (1 - alpha)\n",
    "    direction_out = t1 / norm1 * alpha + t2 / norm2 * (1 - alpha)\n",
    "    return torch.from_numpy(direction_out / (np.linalg.norm(direction_out) + 1e-8) * norm_out).cuda()\n",
    "\n",
    "def generate_interpolations(latent_noise_pair0,\n",
    "                            latent_noise_pair1,\n",
    "                            num_points,\n",
    "                            interpolation_type=\"spherical\",\n",
    "                            **kwargs):\n",
    "    if interpolation_type == \"spherical\":\n",
    "        interp_fn = spherp\n",
    "    elif interpolation_type == \"linear\":\n",
    "        interp_fn = lerp\n",
    "    else:\n",
    "        raise ValueError(interpolation_type)\n",
    "\n",
    "    latent0, noise0 = latent_noise_pair0\n",
    "    latent1, noise1 = latent_noise_pair1\n",
    "\n",
    "    imgs = []\n",
    "    for alpha in np.linspace(1, 0, num_points):\n",
    "        latent_tmp = interp_fn(latent0, latent1, alpha)\n",
    "        noise_tmp = [interp_fn(n0, n1, alpha)\n",
    "                     for n0, n1 in zip(noise0, noise1)]\n",
    "        img = model.synthesize(latent_tmp, noise_tmp, **kwargs)\n",
    "        imgs.append(img)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgs_to_animation(imgs, output_path):\n",
    "    assert output_path.endswith(\".mp4\")\n",
    "    tempdir = tempfile.TemporaryDirectory()\n",
    "\n",
    "    for idx, img in enumerate(imgs):\n",
    "        toPIL(img[0]).save(f\"{tempdir.name}/img_{idx:04d}.png\")\n",
    "\n",
    "    subprocess.check_output([\"ffmpeg\", \n",
    "                             \"-y\",  # overwrite output file\n",
    "                             \"-f\", \"image2\", # force format?\n",
    "                             \"-i\", f\"{tempdir.name}/img_%04d.png\",  # input files\n",
    "                             \"-start_number\", \"0\",  # what number to start at\n",
    "                             \"-filter:v\", \"setpts=2.0*PTS\",  # slow down video\n",
    "                             output_path,  # output file\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make grid and interpolations for single image + configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_samples = 25\n",
    "grid_shape = (2, 5)\n",
    "filter_results = True\n",
    "sort_results = False\n",
    "configuration = \"vanilla_pulse\"\n",
    "# configuration = \"perpendicular_projection_optimizer_psi0.7_discloss\"\n",
    "img_name = \"oprah_0\"\n",
    "\n",
    "ref_im = ref_imgs[img_name]\n",
    "\n",
    "all_results = []\n",
    "for _ in range(num_samples * (2 if filter_results else 1)):\n",
    "    extra_kwargs = configuration_to_extra_kwargs(configuration, all_results)\n",
    "    new_kwargs = dict(kwargs)  # make a copy\n",
    "    new_kwargs.update(extra_kwargs)\n",
    "    for j, results in enumerate(model(ref_im=ref_im, \n",
    "                                      **new_kwargs)):\n",
    "        assert j == 0\n",
    "        all_results.append(results)\n",
    "        \n",
    "if filter_results:\n",
    "    all_results = filter_results_with_D(all_results, num_keep=num_samples)\n",
    "if sort_results:\n",
    "    all_results = sortby_D(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_to_grid(all_results, \n",
    "                grid_shape=grid_shape,\n",
    "                img_prefix=f\"{img_name}__{configuration}__tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_imgs = []\n",
    "\n",
    "latent_noise_pairs = [\n",
    "    model.var_list_to_latent_and_noise(res[\"var_list\"], **new_kwargs)\n",
    "    for res in all_results\n",
    "]\n",
    "\n",
    "for idx in range(len(all_results)):\n",
    "    idx2 = (idx + 1) % len(all_results)\n",
    "    imgs = generate_interpolations(\n",
    "        latent_noise_pairs[idx],\n",
    "        latent_noise_pairs[idx2],\n",
    "        num_points=30,\n",
    "        interpolation_type=\"spherical\",\n",
    "        **new_kwargs\n",
    "    )\n",
    "    all_imgs.extend(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "imgs_to_animation(all_imgs,\n",
    "                  f\"{img_name}__{configuration}__tmp.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run all configurations for one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_samples = 25\n",
    "grid_shape = (5, 5)\n",
    "filter_results = False\n",
    "sort_results = False\n",
    "all_all_results = collections.defaultdict(dict)\n",
    "\n",
    "for img_name in [\"oprah_0\"]:\n",
    "    for configuration in configurations:\n",
    "        img_prefix = f\"{img_name}__{configuration}\"\n",
    "        print(\"Starting: \" + img_prefix)\n",
    "\n",
    "        ref_im = ref_imgs[img_name]\n",
    "\n",
    "        all_results = []\n",
    "        for _ in range(num_samples):\n",
    "            extra_kwargs = configuration_to_extra_kwargs(configuration, all_results)\n",
    "            new_kwargs = dict(kwargs)  # make a copy\n",
    "            new_kwargs.update(extra_kwargs)\n",
    "            for j, results in enumerate(model(ref_im=ref_im, \n",
    "                                              **new_kwargs)):\n",
    "                assert j == 0\n",
    "                all_results.append(results)\n",
    "\n",
    "        if filter_results:\n",
    "            all_results = filter_results_with_D(all_results, num_keep=num_samples)\n",
    "        if sort_results:\n",
    "            all_results = sortby_D(all_results)\n",
    "\n",
    "        all_all_results[img_name][configuration] = all_results\n",
    "        results_to_grid(all_results, \n",
    "                        grid_shape=grid_shape,\n",
    "                        img_prefix=img_prefix,\n",
    "                        out_dir=\"final_runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run all configurations for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_samples = 25\n",
    "grid_shape = (5, 5)\n",
    "filter_results = False\n",
    "sort_results = False\n",
    "all_all_results = collections.defaultdict(dict)\n",
    "\n",
    "for img_name in ref_imgs.keys():\n",
    "    for configuration in configurations:\n",
    "        img_prefix = f\"{img_name}__{configuration}\"\n",
    "        print(\"Starting: \" + img_prefix)\n",
    "\n",
    "        ref_im = ref_imgs[img_name]\n",
    "\n",
    "        all_results = []\n",
    "        for _ in range(num_samples):\n",
    "            extra_kwargs = configuration_to_extra_kwargs(configuration, all_results)\n",
    "            new_kwargs = dict(kwargs)  # make a copy\n",
    "            new_kwargs.update(extra_kwargs)\n",
    "            for j, results in enumerate(model(ref_im=ref_im, \n",
    "                                              **new_kwargs)):\n",
    "                assert j == 0\n",
    "                all_results.append(results)\n",
    "\n",
    "        if filter_results:\n",
    "            all_results = filter_results_with_D(all_results, num_keep=num_samples)\n",
    "        if sort_results:\n",
    "            all_results = sortby_D(all_results)\n",
    "\n",
    "        all_all_results[img_name][configuration] = all_results\n",
    "        results_to_grid(all_results, \n",
    "                        grid_shape=grid_shape,\n",
    "                        img_prefix=img_prefix,\n",
    "                        out_dir=\"final_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
