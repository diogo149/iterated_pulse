* installation
conda create -n pulse2 -c pytorch -c conda-forge pytorch=1.5.0 dlib pillow jupyter requests scipy torchvision matplotlib
# had to do this because the default pytorch requires a different cuda version
conda install -c pytorch pytorch=1.5.0=py3.8_cuda10.1.243_cudnn7.6.3_0
* TODOs
- [X] chang the drive downloading to locally downloaded files
- [X] iterative generation using perpendicular init
- [X] perpendicular projection optimizer
- [X] try iterative w/ latents only (not noise)
- [X] make grid of samples
  - make grid utility
- [X] make plan of what to run
  - runs w/ 25 samples ?
  - configurations:
    - vanilla_pulse
    - iterative_negation_initialization
    - iterative_perpendicular_initialization
    - perpendicular_projection_optimizer
    - perpendicular_projection_optimizer_only_latents
- [X] try psi = 0.7
- [X] farthest_sampled_initailization
- [X] tried eps = 0.0
- [X] use D to make realistic samples
  - hypothesis: higher number = less real
  - [X] use aux loss
    - "100*L2+0.05*GEOCROSS"
    - try: 0.05 for DISC loss
      - seemed too high
    - try: 0.02
      - still way too high
    - try: 0.01
      - still way too high
      - looks like adversarial examples for D
    - 0.003
  - [X] rejection sampling
- [X] code cleanup
  - add psi=0.7 option
  - add "100*L2+0.05*GEOCROSS+0.01*DISC"
  - flag for rejection sampling
    - filter_results_with_D
  - flag for sortby_D
- [X] run all configs on oprah
- [X] package up code nicely (so that others can use)
- [X] make animation of interpolation of samples
- [X] try min pool
  - D = lambda x: -F.max_pool2d(-x, factor)
* for making combined images
#+BEGIN_SRC python
import PIL
import numpy as np
import os

dir_path = "."
pngs = [f for f in os.listdir(dir_path) if f.endswith(".png")]
v0_suffix = "__vanilla_pulse__grid.png"
v1_suffix = "__perpendicular_projection_optimizer_psi0.7_discloss__grid.png"
has_v0 = [f[:-len(v0_suffix)] for f in pngs if f.endswith(v0_suffix)]
has_v1 = [f[:-len(v1_suffix)] for f in pngs if f.endswith(v1_suffix)]


for prefix in set(has_v0).intersection(has_v1):
    img_v0 = prefix + v0_suffix
    img_v1 = prefix + v1_suffix
    res = prefix + "_combined.png"
    if not os.path.exists(res):
        i0 = PIL.Image.open(img_v0)
        i1 = PIL.Image.open(img_v1)
        assert i0.size == i1.size
        i0 = i0.resize([s // 4 for s in i0.size], resample=PIL.Image.LANCZOS)
        i1 = i1.resize([s // 4 for s in i1.size], resample=PIL.Image.LANCZOS)
        i0 = np.array(i0)
        i1 = np.array(i1)
        border = np.zeros((i0.shape[0], 5, 3), dtype=np.uint8)
        new_i = np.concatenate(([i0, border, i1]), axis=1)
        PIL.Image.fromarray(new_i).save(res)
#+END_SRC
* make combined for each config
#+BEGIN_SRC python
import PIL
import numpy as np
import os

border_size = 5

configs = [f[len("oprah_0__"):-len("__grid.png")] for f in os.listdir(".")
           if f.endswith("__grid.png")]

for config in configs:
    img_v0 = "oprah_0__" + "vanilla_pulse" + "__grid.png"
    if config != "vanilla_pulse":
        img_v1 = "oprah_0__" + config + "__grid.png"
        res = "oprah_0__combined__" + config + ".png"

        if not os.path.exists(res):
            i0 = PIL.Image.open(img_v0)
            i1 = PIL.Image.open(img_v1)
            assert i0.size == i1.size
            i0 = i0.resize([s // 4 for s in i0.size], resample=PIL.Image.LANCZOS)
            i1 = i1.resize([s // 4 for s in i1.size], resample=PIL.Image.LANCZOS)
            i0 = np.array(i0)
            i1 = np.array(i1)
            border = np.zeros((i0.shape[0], border_size, 3), dtype=np.uint8)
            new_i = np.concatenate(([i0, border, i1]), axis=1)
            PIL.Image.fromarray(new_i).save(res)
#+END_SRC
* make combined w/ random noise
#+BEGIN_SRC python
import PIL
import numpy as np
import os

border_size = 50

configs = [f[len("oprah_0__"):-len("__grid.png")] for f in os.listdir(".")
           if f.endswith("__grid.png")]

for config in configs:
    img_v0 = "oprah_0__" + "vanilla_pulse" + "__grid.png"
    if config != "vanilla_pulse":
        img_v1 = "oprah_0__" + config + "__grid.png"
        res = "oprah_0__combined_random__" + config + ".png"

        if not os.path.exists(res):
            i0 = PIL.Image.open(img_v0)
            i1 = PIL.Image.open(img_v1)
            assert i0.size == i1.size
            i0 = i0.resize([s // 4 for s in i0.size], resample=PIL.Image.LANCZOS)
            i1 = i1.resize([s // 4 for s in i1.size], resample=PIL.Image.LANCZOS)
            i0 = np.array(i0)
            i1 = np.array(i1)
            border = np.zeros((i0.shape[0], border_size, 3), dtype=np.uint8)
            border += np.random.randint(256, size=border.shape, dtype=np.uint8)
            new_i = np.concatenate(([i0, border, i1]), axis=1)
            PIL.Image.fromarray(new_i).save(res)
#+END_SRC
* snippet for minpool-ed faces
#+BEGIN_SRC python
%%time

unaligned_path = "unaligned_faces/"
aligned_faces_size = 32
f = "shape_predictor_68_face_landmarks.dat"
predictor = dlib.shape_predictor(f)

for im in Path(unaligned_path).glob("*.*"):
    print(im)
    faces = align_face(str(im), predictor)

    for i, face in enumerate(faces):
        target_path = Path("aligned_faces_minpool") / (im.stem + f"_{i}.png")
        if not os.path.exists(target_path):
            print(face._size)
            if aligned_faces_size is not None:
                factor = 1024 // aligned_faces_size
                assert aligned_faces_size * factor == 1024
                D = lambda x: -F.max_pool2d(-x, factor)
                face_tensor = torchvision.transforms.ToTensor()(face).unsqueeze(0).cuda()
                face_tensor_lr = D(face_tensor)[0].cpu().detach().clamp(0, 1)
                face = torchvision.transforms.ToPILImage()(face_tensor_lr)

            face.save(target_path)
#+END_SRC
* snippet for side-by-side interpolation video
#+BEGIN_SRC python
%%time

num_samples = 25
grid_shape = (5, 5)
filter_results = True
sort_results = False
configuration = "vanilla_pulse"
img_name = "oprah_0"

ref_im = ref_imgs[img_name]

all_results = []
for _ in range(num_samples * (2 if filter_results else 1)):
    extra_kwargs = configuration_to_extra_kwargs(configuration, all_results)
    new_kwargs = dict(kwargs)  # make a copy
    new_kwargs.update(extra_kwargs)
    for j, results in enumerate(model(ref_im=ref_im,
                                      ,**new_kwargs)):
        assert j == 0
        all_results.append(results)

if filter_results:
    all_results = filter_results_with_D(all_results, num_keep=num_samples)
if sort_results:
    all_results = sortby_D(all_results)

all_imgs = []

latent_noise_pairs = [
    model.var_list_to_latent_and_noise(res["var_list"], **new_kwargs)
    for res in all_results
]

for idx in range(len(all_results)):
    idx2 = (idx + 1) % len(all_results)
    imgs = generate_interpolations(
        latent_noise_pairs[idx],
        latent_noise_pairs[idx2],
        num_points=30,
        interpolation_type="spherical",
        ,**new_kwargs
    )
    all_imgs.extend(imgs)

all_imgs1 = all_imgs

configuration = "perpendicular_projection_optimizer_psi0.7_discloss"

all_results = []
for _ in range(num_samples * (2 if filter_results else 1)):
    extra_kwargs = configuration_to_extra_kwargs(configuration, all_results)
    new_kwargs = dict(kwargs)  # make a copy
    new_kwargs.update(extra_kwargs)
    for j, results in enumerate(model(ref_im=ref_im,
                                      ,**new_kwargs)):
        assert j == 0
        all_results.append(results)

if filter_results:
    all_results = filter_results_with_D(all_results, num_keep=num_samples)
if sort_results:
    all_results = sortby_D(all_results)

all_imgs = []

latent_noise_pairs = [
    model.var_list_to_latent_and_noise(res["var_list"], **new_kwargs)
    for res in all_results
]

for idx in range(len(all_results)):
    idx2 = (idx + 1) % len(all_results)
    imgs = generate_interpolations(
        latent_noise_pairs[idx],
        latent_noise_pairs[idx2],
        num_points=30,
        interpolation_type="spherical",
        ,**new_kwargs
    )
    all_imgs.extend(imgs)

all_imgs2 = all_imgs

all_imgs = [torch.cat([img1, img2], dim=3)
            for img1, img2 in zip(all_imgs1, all_imgs2)]

imgs_to_animation(all_imgs,
                  f"{img_name}__{configuration}__sidebyside.mp4")
#+END_SRC
